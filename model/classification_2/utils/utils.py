import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import torch
import tifffile as tiff
from torch.utils.data import Dataset
import torch.nn.functional as F
from tqdm import tqdm
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import copy
import torch.nn as nn
import torch.nn.init as init
import random
from torchvision import transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu") #device ì„¤ì •

target_name_mapping = {
    0: "NF", #Non-Forest, ë¹„ì‚°ë¦¼
    1: "PD", # Pinus densiflora, ì†Œë‚˜ë¬´
    2: "PK", # Pinus koraiensis, ì£ë‚˜ë¬´
    3: "LK", # Larix kaempferi, ë‚™ì—½ì†¡
    4: "QM", # Quercus mongolica, ì‹ ê°ˆë‚˜ë¬´
    5: "QV" # Quercus variabilis, êµ´ì°¸ë‚˜ë¬´
}

# ë‚ ì§œ ë¼ë²¨ ì„¤ì •
dates = ['0201', '0301', '0401', '0415', '0501', '0515', '0601', '0701', '0901', '1001', '1015', '1101']

"""
ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
"""
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler=None, patience = None):
    
    if patience == None:
        patience= num_epochs
        
    train_losses = []
    val_losses = []
    best_val_f1_score = 0
    best_model_state = model.state_dict()  # ì´ˆê¸° ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥
    no_improve_count = 0

    for epoch in range(num_epochs):
        # Training Phase
        model.train()
        train_running_loss = 0.0
        
        train_labels = []
        train_predictions = []

        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Training"):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_running_loss += loss.item() * labels.size(0)  # ë°°ì¹˜ë³„ loss * ê°œìˆ˜ë¡œ ì „ì²´ ì†ì‹¤ ê³„ì‚°
            _, predicted = torch.max(outputs, 1)
            
            train_labels.extend(labels.cpu().numpy())
            train_predictions.extend(predicted.cpu().numpy())
            
        train_loss = train_running_loss / len(train_loader.dataset)  # ì „ì²´ ìƒ˜í”Œ ìˆ˜ë¡œ ë‚˜ëˆ”
        train_losses.append(train_loss)
        
        full_class_labels = np.arange(outputs.shape[1])
        train_report = classification_report(train_labels, train_predictions, labels=full_class_labels, output_dict=True)

        # Validation Phase
        model.eval()
        val_running_loss = 0.0

        val_labels = []
        val_predictions = []
        
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Validation"):
                images, labels = images.to(device), labels.to(device)

                outputs = model(images)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item() * labels.size(0)
                _, predicted = torch.max(outputs, 1)
                
                val_labels.extend(labels.cpu().numpy())
                val_predictions.extend(predicted.cpu().numpy())

        val_loss = val_running_loss / len(val_loader.dataset)
        val_losses.append(val_loss)
        
        val_report = classification_report(val_labels, val_predictions, labels=full_class_labels, output_dict=True)
        
        print(f"\nEpoch [{epoch+1}/{num_epochs}], "
              f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_report['accuracy']:.2f}, Train f1-score: {train_report["macro avg"]["f1-score"]:.2f} "
              f"Val Loss: {val_loss:.4f}, Val Accuracy: {val_report['accuracy']:.2f}, Val f1-score: {val_report["macro avg"]["f1-score"]:.2f}\n")
        
        # Early Stopping & Model Saving
        if best_val_f1_score < val_report["macro avg"]["f1-score"]:
            best_val_f1_score = val_report["macro avg"]["f1-score"]
            best_model_state = copy.deepcopy(model.state_dict())
            no_improve_count = 0
        else:
            no_improve_count += 1

        if no_improve_count >= patience:
            print("Early stopping triggered. Training stopped.")
            break
            
        if scheduler:
            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                scheduler.step(val_loss)  # validation loss ê¸°ì¤€
            else:
                scheduler.step()  # ì¼ë°˜ì ì¸ step()
    
    return best_model_state, train_losses, val_losses

"""
ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•œ í•¨ìˆ˜ë“¤
"""
def evaluate_model_with_cm(model, val_loader, num_classes=6, target_name_mapping=target_name_mapping):
    """
    ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  í˜¼ë™ í–‰ë ¬(Confusion Matrix) ë° ë¶„ë¥˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    ì¶”ê°€ì ìœ¼ë¡œ ì¹¨ì—½ìˆ˜ì™€ í™œì—½ìˆ˜ì˜ ë¶„ë¥˜ë ¥ ë° ë‚´ë¶€ ë¶„ë¥˜ë ¥ì„ ë¶„ì„í•˜ê³  ì´ë¥¼ ë°˜í™˜í•˜ëŠ” ë°ì´í„°í”„ë ˆì„ì— í¬í•¨í•œë‹¤.
    """
    model.eval()
    all_labels = []
    all_predictions = []

    # ê²€ì¦ ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc="Evaluation Progress"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    # ì „ì²´ í´ë˜ìŠ¤ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    full_class_labels = np.arange(num_classes)
    cm = confusion_matrix(all_labels, all_predictions, labels=full_class_labels)
    
    # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=target_name_mapping.values(), yticklabels=target_name_mapping.values())
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()
    
    # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ë¶„ë¥˜ ë¦¬í¬íŠ¸
    target_names = list(target_name_mapping.values())
    report_dict = classification_report(all_labels, all_predictions, labels=full_class_labels, target_names=target_names, digits=3, output_dict=True)
    report_df = pd.DataFrame(report_dict).transpose()
    report_df["task"] = "Overall"
    
    # ì¶”ê°€ì ì¸ ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥
    conifer_vs_broadleaf_report = evaluate_conifer_vs_broadleaf(all_labels, all_predictions) #ì¹¨/í™œ ë¶„ë¥˜ë ¥
    conifer_vs_broadleaf_report["task"] = "Conifer vs Broadleaf"
    
    conifer_report = evaluate_conifer_classification(all_labels, all_predictions) #ì¹¨ì—½ìˆ˜ ë‚´ ë¶„ë¥˜ë ¥
    conifer_report["task"] = "Conifer"
    
    broadleaf_report = evaluate_broadleaf_classification(all_labels, all_predictions) #í™œì—½ìˆ˜ ë‚´ ë¶„ë¥˜ë ¥
    broadleaf_report["task"] = "Broadleaf"
    
    # ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í†µí•©
    additional_metrics = pd.concat([conifer_vs_broadleaf_report, conifer_report, broadleaf_report])
    final_report_df = pd.concat([report_df, additional_metrics])
    
    return final_report_df

# ì¹¨ì—½ìˆ˜ vs í™œì—½ìˆ˜ ë¶„ë¥˜ë ¥ í‰ê°€ í•¨ìˆ˜
def evaluate_conifer_vs_broadleaf(all_labels, all_predictions):
    """
    ì¹¨ì—½ìˆ˜ì™€ í™œì—½ìˆ˜ë¥¼ êµ¬ë¶„í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜.
    Non-Forestë¥¼ ì œì™¸í•œ ë°ì´í„°ì—ì„œ ì¹¨ì—½ìˆ˜ì™€ í™œì—½ìˆ˜ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë¶„ë¥˜í–ˆëŠ”ì§€ë¥¼ í‰ê°€í•œë‹¤.
    """
    conifer_classes = {1, 2, 3}  # ì¹¨ì—½ìˆ˜ í´ë˜ìŠ¤
    broadleaf_classes = {4, 5}  # í™œì—½ìˆ˜ í´ë˜ìŠ¤
    
    # Non-Forest ì œì™¸ í›„ ì¹¨ì—½ìˆ˜ì™€ í™œì—½ìˆ˜ë¡œë§Œ ê·¸ë£¹í•‘
    valid_indices = [i for i, (label, pred) in enumerate(zip(all_labels, all_predictions)) if (label in conifer_classes or label in broadleaf_classes) and (pred in conifer_classes or pred in broadleaf_classes)]
    true_labels = [1 if all_labels[i] in conifer_classes else 2 for i in valid_indices]
    pred_labels = [1 if all_predictions[i] in conifer_classes else 2 for i in valid_indices]
    
    cm = confusion_matrix(true_labels, pred_labels, labels=[1, 2])
    
    plt.figure(figsize=(7, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Conifer", "Broadleaf"], yticklabels=["Conifer", "Broadleaf"])
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Conifer vs Broadleaf Classification')
    plt.show()
    
    return pd.DataFrame(classification_report(true_labels, pred_labels, target_names=["Conifer", "Broadleaf"], digits=3, output_dict=True)).transpose()

# ì¹¨ì—½ìˆ˜ ë‚´ë¶€ ë¶„ë¥˜ë ¥ í‰ê°€ í•¨ìˆ˜
def evaluate_conifer_classification(all_labels, all_predictions):
    """
    ì¹¨ì—½ìˆ˜ ë‚´ë¶€ì—ì„œ ê°œë³„ í´ë˜ìŠ¤ë¥¼ êµ¬ë¶„í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜.
    """
    conifer_classes = {1, 2, 3}
    valid_indices = [i for i, (label, pred) in enumerate(zip(all_labels, all_predictions)) if label in conifer_classes and pred in conifer_classes]
    true_labels = [all_labels[i] for i in valid_indices]
    pred_labels = [all_predictions[i] for i in valid_indices]
    
    cm = confusion_matrix(true_labels, pred_labels, labels=[1, 2, 3])
    target_names = [target_name_mapping[1], target_name_mapping[2], target_name_mapping[3]]
    
    plt.figure(figsize=(7, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=target_names, yticklabels=target_names)
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Conifer Classification')
    plt.show()
    
    return pd.DataFrame(classification_report(true_labels, pred_labels, target_names=target_names, digits=3, output_dict=True)).transpose()

# í™œì—½ìˆ˜ ë‚´ë¶€ ë¶„ë¥˜ë ¥ í‰ê°€ í•¨ìˆ˜
def evaluate_broadleaf_classification(all_labels, all_predictions):
    """
    í™œì—½ìˆ˜ ë‚´ë¶€ì—ì„œ ê°œë³„ í´ë˜ìŠ¤ë¥¼ êµ¬ë¶„í•˜ëŠ” ëŠ¥ë ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜.
    """
    broadleaf_classes = {4, 5}
    valid_indices = [i for i, (label, pred) in enumerate(zip(all_labels, all_predictions)) if label in broadleaf_classes and pred in broadleaf_classes]
    true_labels = [all_labels[i] for i in valid_indices]
    pred_labels = [all_predictions[i] for i in valid_indices]
    
    cm = confusion_matrix(true_labels, pred_labels, labels=[4, 5])
    target_names = [target_name_mapping[4], target_name_mapping[5]]
    
    plt.figure(figsize=(7, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=target_names, yticklabels=target_names)
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Broadleaf Classification')
    plt.show()
    
    return pd.DataFrame(classification_report(true_labels, pred_labels, target_names=target_names, digits=3, output_dict=True)).transpose()

#rfí‰ê°€ë¥¼ ìœ„í•œ í•¨ìˆ˜
def evaluate_rf_model_with_cm(model, val_loader, num_classes=6, target_name_mapping=target_name_mapping):
    """
    Random Forest ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  í˜¼ë™ í–‰ë ¬(Confusion Matrix) ë° ë¶„ë¥˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜.
    ì¶”ê°€ì ìœ¼ë¡œ ì¹¨ì—½ìˆ˜ì™€ í™œì—½ìˆ˜ì˜ ë¶„ë¥˜ë ¥ ë° ë‚´ë¶€ ë¶„ë¥˜ë ¥ì„ ë¶„ì„í•˜ê³  ì´ë¥¼ ë°˜í™˜í•˜ëŠ” ë°ì´í„°í”„ë ˆì„ì— í¬í•¨í•œë‹¤.
    """
    all_labels = []
    all_predictions = []

    # ê²€ì¦ ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    for X_batch, y_batch in tqdm(val_loader, desc="Evaluation Progress"):
        X_batch = X_batch.numpy()  # NumPyë¡œ ë³€í™˜ (RandomForestëŠ” NumPy ë°°ì—´ì„ ì‚¬ìš©)
        y_batch = y_batch.numpy()
        
        # ì˜ˆì¸¡
        preds = model.predict(X_batch)  # RandomForest ì˜ˆì¸¡

        all_labels.extend(y_batch)
        all_predictions.extend(preds)

    # ì „ì²´ í´ë˜ìŠ¤ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    full_class_labels = np.arange(num_classes)
    cm = confusion_matrix(all_labels, all_predictions, labels=full_class_labels)
    
    # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=target_name_mapping.values(), yticklabels=target_name_mapping.values())
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.title('Confusion Matrix')
    plt.show()
    
    # ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ë¶„ë¥˜ ë¦¬í¬íŠ¸
    target_names = list(target_name_mapping.values())
    report_dict = classification_report(all_labels, all_predictions, labels=full_class_labels, target_names=target_names, digits=3, output_dict=True)
    report_df = pd.DataFrame(report_dict).transpose()
    report_df["task"] = "Overall"
    
    # ì¶”ê°€ì ì¸ ë¶„ì„ ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥
    conifer_vs_broadleaf_report = evaluate_conifer_vs_broadleaf(all_labels, all_predictions)  # ì¹¨/í™œ ë¶„ë¥˜ë ¥
    conifer_vs_broadleaf_report["task"] = "Conifer vs Broadleaf"
    
    conifer_report = evaluate_conifer_classification(all_labels, all_predictions)  # ì¹¨ì—½ìˆ˜ ë‚´ ë¶„ë¥˜ë ¥
    conifer_report["task"] = "Conifer"
    
    broadleaf_report = evaluate_broadleaf_classification(all_labels, all_predictions)  # í™œì—½ìˆ˜ ë‚´ ë¶„ë¥˜ë ¥
    broadleaf_report["task"] = "Broadleaf"
    
    # ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í†µí•©
    additional_metrics = pd.concat([conifer_vs_broadleaf_report, conifer_report, broadleaf_report])
    final_report_df = pd.concat([report_df, additional_metrics])
    
    return final_report_df


"""
Dataset í´ë˜ìŠ¤
"""
class TiffDataset(Dataset):
    def __init__(self, large_tif_dir, file_list, label_file, patch_size=3, box_filter_fn=None, transform=None):
        """
        Args:
            large_tif_dir (str): ì—¬ëŸ¬ ê°œì˜ í° TIFF íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œ.
            file_list (list of str): ì²˜ë¦¬í•  ì›ì²œ ë°ì´í„° íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸.
            label_file (str): ë¼ë²¨ ì •ë³´ë¥¼ ë‹´ì€ CSV íŒŒì¼ ê²½ë¡œ ("file", "x_pos", "y_pos", "label" ì—´ í¬í•¨).
            patch_size (int): ìŠ¬ë¼ì´ì‹±í•  ì´ë¯¸ì§€ì˜ í¬ê¸° (í•­ìƒ í™€ìˆ˜ì—¬ì•¼ í•¨).
            box_filter_fn (callable, optional): ë°•ìŠ¤ ë²ˆí˜¸ í•„í„°ë§ í•¨ìˆ˜.
            transform (callable, optional): ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì— ì‚¬ìš©í•  í•¨ìˆ˜.
        """
        if patch_size % 2 == 0:
            raise ValueError("patch_sizeëŠ” í™€ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        self.large_tif_dir = large_tif_dir
        self.file_list = set(file_list)
        self.label_df = pd.read_csv(label_file)

        self.box_filter_fn = box_filter_fn or (lambda box_number: True)
        self.label_df = self.label_df[self.label_df['file'].isin(self.file_list)].reset_index(drop=True)
        self.label_df = self.label_df[self.label_df['box_number'].apply(self.box_filter_fn)].reset_index(drop=True)

        self.patch_size = patch_size
        self.half_size = patch_size // 2
        self.transform = transform

        self.image_cache = {}

        # ìœ íš¨í•œ ìƒ˜í”Œë§Œ ë‚¨ê¸´ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        self.valid_indices = self._filter_valid_indices()

    def _load_image(self, file_name):
        if file_name not in self.image_cache:
            file_path = os.path.join(self.large_tif_dir, file_name)
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"Image file '{file_path}' not found.")
            self.image_cache[file_name] = tiff.imread(file_path)
        return self.image_cache[file_name]

    def _filter_valid_indices(self):
        """ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ” ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ ì €ì¥"""
        valid_indices = []
        for idx, row in self.label_df.iterrows():
            file_name = row["file"]
            x, y = row["x_pos"], row["y_pos"]

            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            try:
                image = self._load_image(file_name)
                image_height, image_width = image.shape[:2]

                x_start, y_start = x - self.half_size, y - self.half_size
                x_end, y_end = x + self.half_size + 1, y + self.half_size + 1

                # ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ” ê²½ìš°ë§Œ ìœ íš¨í•œ ì¸ë±ìŠ¤ë¡œ ì €ì¥
                if 0 <= x_start and 0 <= y_start and x_end <= image_width and y_end <= image_height:
                    valid_indices.append(idx)
            except FileNotFoundError:
                continue  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ

        return valid_indices

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx):
        row = self.label_df.iloc[self.valid_indices[idx]]
        file_name, x, y, label = row["file"], row["x_pos"], row["y_pos"], row["label"]

        image = self._load_image(file_name)
        x_start, y_start = x - self.half_size, y - self.half_size
        x_end, y_end = x + self.half_size + 1, y + self.half_size + 1

        patch = image[y_start:y_end, x_start:x_end]

        if self.transform:
            patch = self.transform(patch)

        return patch, label

"""
ê¸°ë³¸ ë°ì´í„° transform
"""
class ReshapeTransform:
    """(12*bands, 3, 3) â†’ (12, bands, 3, 3) ë³€í™˜"""
    def __init__(self, bands, patch_size, time=12):
        self.bands = bands
        self.patch_size = patch_size
        self.time = time

    def __call__(self, x):
        #return x.view(self.bands, self.time, self.patch_size, self.patch_size)
        return x.view(self.time, self.bands, self.patch_size, self.patch_size).permute(1,0,2,3)

def scale_up_planet_channels(x):
    x[:3] *= 5  # ì²« 3ê°œ ì±„ë„ì„ 5ë°° ìŠ¤ì¼€ì¼ë§
    return x

def base_transform(bands, patch_size, scale_channels=True):
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Lambda(lambda x: x.float()),  # uint16 â†’ float ë³€í™˜
        ReshapeTransform(bands, patch_size),  # (bands*time, height, width) â†’ (bands, time, height, width)
        transforms.Lambda(scale_up_planet_channels)  # ì²« 3ê°œ ì±„ë„ì„ 5ë°° í™•ëŒ€
    ])
    
#he initializer í•¨ìˆ˜
def he_init_weights(m):
    """
    Applies He (Kaiming) initialization to Conv layers and Linear layers.
    
    - Conv2d, Conv3d: He Normal Initialization with fan_out mode
    - Linear: He Uniform Initialization with fan_in mode
    - BatchNorm: gamma = 1, beta = 0
    - Biases (if exist): Initialized to zero
    """
    if isinstance(m, (nn.Conv2d, nn.Conv3d)):
        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
        if m.bias is not None:
            init.zeros_(m.bias)
    
    elif isinstance(m, nn.Linear):
        init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')
        if m.bias is not None:
            init.zeros_(m.bias)

    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm3d)):
        init.constant_(m.weight, 1)
        init.constant_(m.bias, 0)

"""
PSA í•¨ìˆ˜
"""
import torch
import random
from tqdm import tqdm

def psa_dim(model, data_loader, num_repeats=1, perturbation_strength=0.8, target_dims=None, normalize=True, TP_only=True):
    model.eval()

    sample_batch, _ = next(iter(data_loader))
    num_dims = len(sample_batch.shape) - 1
    dim_names = [f"dim_{i}" for i in range(1, num_dims + 1)]

    # ì¡°ì‚¬í•  ì°¨ì›ì„ ì„¤ì • (ê¸°ë³¸: ëª¨ë“  ì°¨ì›)
    if target_dims is None:
        target_dims = dim_names
    else:
        target_dims = [f"dim_{i}" for i in target_dims]

    overall_scores = {dim: 0.0 for dim in target_dims}
    per_class_scores = {}
    TP_count = {}  # TP ê°œìˆ˜ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    total_samples = 0

    for X_batch, targets in tqdm(data_loader, desc="Processing batches"):
        batch_size = X_batch.shape[0]
        total_samples += batch_size
        X_batch = X_batch.to(next(model.parameters()).device)
        targets = targets.to(X_batch.device)

        logit_original = model(X_batch).detach()
        predictions = logit_original.argmax(dim=1)
        num_classes = logit_original.shape[1]

        if not per_class_scores:
            per_class_scores = {cls: {dim: 0.0 for dim in target_dims} for cls in range(num_classes)}
            TP_count = {cls: 0 for cls in range(num_classes)}

        for dim_name in target_dims:
            dim_idx = dim_names.index(dim_name) + 1  # 1-based index
            total_abs_error = 0.0
            class_abs_error = {cls: 0.0 for cls in range(num_classes)}

            for _ in range(num_repeats):
                X_perturbed = X_batch.clone().detach()
                num_swap = max(1, int(X_perturbed.shape[dim_idx] * perturbation_strength))
                swap_indices = random.sample(range(X_perturbed.shape[dim_idx]), num_swap)
                permutation = random.sample(swap_indices, len(swap_indices))

                X_perturbed.index_copy_(dim_idx, torch.tensor(swap_indices, device=X_batch.device),
                                        X_perturbed.index_select(dim_idx, torch.tensor(permutation, device=X_batch.device)))

                logit_perturbed = model(X_perturbed).detach()
                abs_error = torch.abs(logit_original - logit_perturbed)  # ì›ë³¸ê³¼ ë³€í˜•ëœ ì˜ˆì¸¡ê°’ì˜ ì ˆëŒ€ ì°¨ì´ ê³„ì‚°

                total_abs_error += abs_error.mean().item() * batch_size

                for cls in range(num_classes):
                    if TP_only:
                        TP_mask = (predictions == targets) & (targets == cls)
                        TP_sample_count = TP_mask.sum().item()
                        if TP_sample_count > 0:
                            TP_count[cls] += TP_sample_count
                            class_abs_error[cls] += abs_error[TP_mask].sum().item()  # TP ê°œë³„ ìƒ˜í”Œë“¤ì˜ ì—ëŸ¬ í•©ì‚°
                    else:
                        class_abs_error[cls] += abs_error[:, cls].sum().item()

            overall_scores[dim_name] += total_abs_error / num_repeats
            for cls in range(num_classes):
                per_class_scores[cls][dim_name] += class_abs_error[cls] / num_repeats

    for key in overall_scores:
        overall_scores[key] /= total_samples

    for cls in per_class_scores:
        if TP_only and TP_count[cls] > 0:
            for key in per_class_scores[cls]:
                per_class_scores[cls][key] /= TP_count[cls]  # TP ìƒ˜í”Œ ê°œìˆ˜ë¡œ ë‚˜ëˆ„ì–´ í‰ê·  ê³„ì‚°
        else:
            for key in per_class_scores[cls]:
                per_class_scores[cls][key] /= total_samples

    # ğŸ”¹ ì„ íƒí•œ ì°¨ì›ë§Œ ì •ê·œí™”í•˜ì—¬ í•©ì´ 1ì´ ë˜ë„ë¡ ì¡°ì •
    if normalize:
        total_score = sum(overall_scores.values())
        overall_scores = {key: value / total_score for key, value in overall_scores.items()} if total_score > 0 else overall_scores

        for cls in per_class_scores:
            class_total_score = sum(per_class_scores[cls].values())
            per_class_scores[cls] = {key: value / class_total_score for key, value in per_class_scores[cls].items()} if class_total_score > 0 else per_class_scores[cls]

    return {"overall": overall_scores, "per_class": per_class_scores}


def plot_psa_dim_scores(overall_scores, per_class_scores, dim_labels=["Bands", "Time", "Space"]):
    # Overall Dimension Importance (Bar Chart)
    combined_scores = {
        "Bands": overall_scores['dim_1'],
        "Time": overall_scores['dim_2'],
        "Space": overall_scores['dim_3'] + overall_scores['dim_4']
    }

    plt.figure(figsize=(8, 5))
    plt.bar(dim_labels, combined_scores.values(), color='skyblue')
    plt.xlabel("Dimension")
    plt.ylabel("Sensitivity Score")
    plt.title("Overall Dimension Sensitivity")
    plt.xticks(rotation=45)
    plt.show()

    # Per-Class Importance (Heatmap)
    per_class_df = {}
    for cls, scores in per_class_scores.items():
        per_class_df[target_name_mapping.get(cls, f"Class {cls}")] = [
            scores['dim_1'],
            scores['dim_2'],
            scores['dim_3'] + scores['dim_4']  # Space
        ]
        
    plt.figure(figsize=(10, 6))
    sns.heatmap(list(per_class_df.values()), annot=True, cmap="Blues", xticklabels=dim_labels, yticklabels=list(per_class_df.keys()))
    plt.xlabel("Dimension")
    plt.ylabel("Class")
    plt.title("Per-Class Dimension Sensitivity")
    plt.xticks(rotation=45)
    plt.show()


#perturbation ê´€ë ¨ ì½”ë“œ
def psa_bands_time(model, dataloader, num_classes=6, num_repeats=1):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()

    band, time = 4, 12  # ë°ì´í„°ì˜ ë°´ë“œ ìˆ˜ì™€ ì‹œê°„ ìŠ¤í… ìˆ˜

    # ê²°ê³¼ ì €ì¥ ë³€ìˆ˜
    total_sensitivity_map = torch.zeros((num_classes, band, time), device=device)
    total_count_map = torch.zeros((num_classes, band, time), device=device)

    total_band_sensitivity = torch.zeros((num_classes, band), device=device)
    total_band_count = torch.zeros((num_classes, band), device=device)

    total_time_sensitivity = torch.zeros((num_classes, time), device=device)
    total_time_count = torch.zeros((num_classes, time), device=device)

    with torch.no_grad():
        for repeat in range(num_repeats):
            sensitivity_map = torch.zeros((num_classes, band, time), device=device)
            count_map = torch.zeros((num_classes, band, time), device=device)

            band_sensitivity = torch.zeros((num_classes, band), device=device)
            band_count = torch.zeros((num_classes, band), device=device)

            time_sensitivity = torch.zeros((num_classes, time), device=device)
            time_count = torch.zeros((num_classes, time), device=device)

            for data, labels in tqdm(dataloader, desc=f"Experiment {repeat+1}/{num_repeats}"):
                data, labels = data.to(device), labels.to(device)
                B, Band, Time, H, W = data.shape

                # 1. ì›ë³¸ ì˜ˆì¸¡ê°’ ì €ì¥
                original_logits = model(data)
                original_preds = original_logits.argmax(dim=1)

                # 2. True Positive(TP) ë§ˆìŠ¤í¬ ìƒì„±
                tp_mask = (original_preds == labels)

                # 3. band & time ê°œë³„ êµë€ (Zero-out)
                for b in range(band):
                    for t in range(time):
                        perturbed_data = data.clone()
                        perturbed_data[:, b, t] = 0  # ì™„ì „ ë¬´íš¨í™”

                        perturbed_logits = model(perturbed_data)
                        abs_error = torch.abs(original_logits - perturbed_logits)  # ì ˆëŒ€ê°’ ì˜¤ì°¨ ê³„ì‚°

                        for c in range(num_classes):
                            class_mask = (original_preds == c)
                            valid_mask = tp_mask & class_mask  # TP ì¤‘ í•´ë‹¹ í´ë˜ìŠ¤ ë°ì´í„° ì„ íƒ

                            sensitivity_map[c, b, t] += abs_error[:, c][valid_mask].sum()
                            count_map[c, b, t] += valid_mask.sum()  # TP ê°œìˆ˜ ëˆ„ì 

                # 4. band ì „ì²´ë¥¼ Zero-outí•˜ì—¬ ë¯¼ê°ë„ ì¸¡ì •
                for b in range(band):
                    perturbed_data = data.clone()
                    perturbed_data[:, b] = 0  # ì™„ì „ ë¬´íš¨í™”

                    perturbed_logits = model(perturbed_data)
                    abs_error = torch.abs(original_logits - perturbed_logits)

                    for c in range(num_classes):
                        class_mask = (original_preds == c)
                        valid_mask = tp_mask & class_mask

                        band_sensitivity[c, b] += abs_error[:, c][valid_mask].sum()
                        band_count[c, b] += valid_mask.sum()

                # 5. time ì „ì²´ë¥¼ Zero-outí•˜ì—¬ ë¯¼ê°ë„ ì¸¡ì •
                for t in range(time):
                    perturbed_data = data.clone()
                    perturbed_data[:, :, t] = 0  # ì™„ì „ ë¬´íš¨í™”

                    perturbed_logits = model(perturbed_data)
                    abs_error = torch.abs(original_logits - perturbed_logits)

                    for c in range(num_classes):
                        class_mask = (original_preds == c)
                        valid_mask = tp_mask & class_mask

                        time_sensitivity[c, t] += abs_error[:, c][valid_mask].sum()
                        time_count[c, t] += valid_mask.sum()

            # ë°˜ë³µ ì‹¤í—˜ ê²°ê³¼ ëˆ„ì 
            total_sensitivity_map += sensitivity_map
            total_count_map += count_map

            total_band_sensitivity += band_sensitivity
            total_band_count += band_count

            total_time_sensitivity += time_sensitivity
            total_time_count += time_count

    # **ì •ê·œí™” (ê°œìˆ˜ë¡œ ë‚˜ëˆ„ê¸°)**
    total_sensitivity_map = torch.where(total_count_map > 0, total_sensitivity_map / total_count_map, total_sensitivity_map)
    total_band_sensitivity = torch.where(total_band_count > 0, total_band_sensitivity / total_band_count, total_band_sensitivity)
    total_time_sensitivity = torch.where(total_time_count > 0, total_time_sensitivity / total_time_count, total_time_sensitivity)

    return (
        total_sensitivity_map.cpu().numpy(),  # (num_classes, band, time)
        total_band_sensitivity.cpu().numpy(),  # (num_classes, band)
        total_time_sensitivity.cpu().numpy()  # (num_classes, time)
    )

def add_noise(data, noise_level=1.0):
    """
    ë°ì´í„°ì— ëœë¤ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜.

    Args:
        data (torch.Tensor): ì…ë ¥ ë°ì´í„° (Bands, Time, Height, Width)
        noise_level (float): ë…¸ì´ì¦ˆ ê°•ë„ ê³„ìˆ˜

    Returns:
        torch.Tensor: ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ ë°ì´í„°
    """
    noise = (torch.rand_like(data) * 2 - 1) * (data * noise_level)
    return data + noise

def evaluate_perturbation(model, dataloader, num_classes=6, noise_level=0.1, num_repeats=1):
    """
    ëª¨ë¸ì˜ êµë€(ë…¸ì´ì¦ˆ) ì˜í–¥ í‰ê°€ ë° ì¤‘ìš”ë„ íˆíŠ¸ë§µ ìƒì„± (ê¸°ì¡´ + ìƒˆë¡œìš´ ë°©ë²• í¬í•¨)

    Args:
        model (torch.nn.Module): í•™ìŠµëœ ëª¨ë¸
        dataloader (torch.utils.data.DataLoader): ë°ì´í„° ë¡œë”
        num_classes (int): í´ë˜ìŠ¤ ê°œìˆ˜
        noise_level (float): ë…¸ì´ì¦ˆ ê°•ë„
        num_repeats (int): ë°˜ë³µ ì‹¤í—˜ íšŸìˆ˜

    Returns:
        tuple:
            - íˆíŠ¸ë§µ (num_classes, band, time)
            - count_map (num_classes, band, time)
            - bandë³„ ì¤‘ìš”ë„ (num_classes, band)
            - timeë³„ ì¤‘ìš”ë„ (num_classes, time)
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()

    band, time = 4, 12  # ë°ì´í„°ì˜ ë°´ë“œ ìˆ˜ì™€ ì‹œê°„ ìŠ¤í… ìˆ˜

    # ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜
    total_heatmap = torch.zeros((num_classes, band, time), device=device)
    total_count_map = torch.zeros((num_classes, band, time), device=device)
    total_band_importance = torch.zeros((num_classes, band), device=device)
    total_time_importance = torch.zeros((num_classes, time), device=device)

    with torch.no_grad():
        for repeat in range(num_repeats):
            heatmap = torch.zeros((num_classes, band, time), device=device)
            band_importance = torch.zeros((num_classes, band), device=device)
            time_importance = torch.zeros((num_classes, time), device=device)

            for data, labels in tqdm(dataloader, desc=f"Experiment {repeat+1}/{num_repeats}"):
                data, labels = data.to(device), labels.to(device)
                B, Band, Time, H, W = data.shape

                # 1. ì›ë³¸ ì˜ˆì¸¡ê°’ ì €ì¥
                original_logits = model(data)
                original_preds = original_logits.argmax(dim=1)

                # 2. True Positive(TP) ë§ˆìŠ¤í¬ ìƒì„±
                tp_mask = (original_preds == labels)

                # 3. ê¸°ì¡´ ë°©ë²•: band, timeì˜ íŠ¹ì • ê°’ë§Œ êµë€
                for b in range(band):
                    for t in range(time):
                        perturbed_data = data.clone()
                        perturbed_data[:, b, t] = add_noise(perturbed_data[:, b, t], noise_level)

                        perturbed_logits = model(perturbed_data)
                        mse_loss = F.mse_loss(original_logits, perturbed_logits, reduction='none').mean(dim=1)

                        for c in range(num_classes):
                            class_mask = (original_preds == c)
                            valid_mask = tp_mask & class_mask
                            heatmap[c, b, t] += mse_loss[valid_mask].sum()

                # 4. ìƒˆë¡œìš´ ë°©ë²• 1ï¸âƒ£: band ì „ì²´ë¥¼ êµë€í•˜ì—¬ ì¤‘ìš”ë„ ì¸¡ì •
                for b in range(band):
                    perturbed_data = data.clone()
                    perturbed_data[:, b] = add_noise(perturbed_data[:, b], noise_level)

                    perturbed_logits = model(perturbed_data)
                    mse_loss = F.mse_loss(original_logits, perturbed_logits, reduction='none').mean(dim=1)

                    for c in range(num_classes):
                        class_mask = (original_preds == c)
                        valid_mask = tp_mask & class_mask
                        band_importance[c, b] += mse_loss[valid_mask].sum()

                # 5. ìƒˆë¡œìš´ ë°©ë²• 2ï¸âƒ£: time ì „ì²´ë¥¼ êµë€í•˜ì—¬ ì¤‘ìš”ë„ ì¸¡ì •
                for t in range(time):
                    perturbed_data = data.clone()
                    perturbed_data[:, :, t] = add_noise(perturbed_data[:, :, t], noise_level)

                    perturbed_logits = model(perturbed_data)
                    mse_loss = F.mse_loss(original_logits, perturbed_logits, reduction='none').mean(dim=1)

                    for c in range(num_classes):
                        class_mask = (original_preds == c)
                        valid_mask = tp_mask & class_mask
                        time_importance[c, t] += mse_loss[valid_mask].sum()

            # ë°˜ë³µ ì‹¤í—˜ ê²°ê³¼ ëˆ„ì 
            total_heatmap += heatmap
            total_band_importance += band_importance
            total_time_importance += time_importance

    # í‰ê·  ë‚´ê¸°
    total_heatmap /= num_repeats
    total_band_importance /= num_repeats
    total_time_importance /= num_repeats

    # íˆíŠ¸ë§µ ì •ê·œí™” (ê¸°ì¡´ ë°©ì‹)
    for c in range(num_classes):
        if total_heatmap[c].sum() > 0:
            total_heatmap[c] /= total_heatmap[c].sum()
            total_heatmap[c] *= (band * time)

    # ìƒˆë¡œìš´ ë°©ì‹ ì •ê·œí™” (band, time ê°ê° ì •ê·œí™”)
    for c in range(num_classes):
        if total_band_importance[c].sum() > 0:
            total_band_importance[c] /= total_band_importance[c].sum()
            total_band_importance[c] *= band

        if total_time_importance[c].sum() > 0:
            total_time_importance[c] /= total_time_importance[c].sum()
            total_time_importance[c] *= time

    return (
        total_heatmap.cpu().numpy(),  # (num_classes, band, time)
        total_band_importance.cpu().numpy(),  # (num_classes, band)
        total_time_importance.cpu().numpy()  # (num_classes, time)
    )


def plot_psa_maps(importance_maps, band_importance, time_importance):
    """
    ì¤‘ìš”ë„ ë§µì„ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜

    Args:
        importance_maps (np.array): (num_classes, num_bands, num_times) í˜•íƒœì˜ ì¤‘ìš”ë„ ë§µ
        band_importance (np.array): (num_classes, num_bands) ë°´ë“œë³„ ì¤‘ìš”ë„ (ëª¨ë“  ê°’ êµë€)
        time_importance (np.array): (num_classes, num_times) ì‹œê¸°ë³„ ì¤‘ìš”ë„ (ëª¨ë“  ê°’ êµë€)
    """
    num_classes, num_bands, num_times = importance_maps.shape

    # í´ë˜ìŠ¤ë³„ë¡œ 3ê°œì˜ ê·¸ë˜í”„ (íˆíŠ¸ë§µ, êµë€ëœ ë°´ë“œ ì¤‘ìš”ë„, êµë€ëœ ì‹œê¸° ì¤‘ìš”ë„)
    fig, axes = plt.subplots(num_classes, 3, figsize=(18, 4 * num_classes))

    for cls in range(num_classes):
        class_name = target_name_mapping[cls]  # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°

        # 1ï¸âƒ£ ì‹œê¸°ë³„ & ë°´ë“œë³„ ì¤‘ìš”ë„ íˆíŠ¸ë§µ
        ax = axes[cls, 0]
        sns.heatmap(importance_maps[cls], cmap="coolwarm", annot=True, fmt=".2f", ax=ax)
        ax.set_title(f"{class_name}: Temporal & Band Importance")
        ax.set_xlabel("Time (Dates)")
        ax.set_ylabel("Bands (B, G, R, NIR)")
        ax.set_xticks(np.arange(num_times))
        ax.set_xticklabels(dates, rotation=45)  # ë‚ ì§œ ë¼ë²¨ ì ìš©

        # 2ï¸âƒ£ ìƒˆë¡œìš´ ë°©ì‹: êµë€ëœ ë°´ë“œë³„ ì¤‘ìš”ë„ ë°” ê·¸ë˜í”„
        ax = axes[cls, 1]
        ax.bar(["B", "G", "R", "NIR"], band_importance[cls], color=["blue", "green", "red", "purple"])
        ax.set_title(f"{class_name}: Band Importance")
        ax.set_ylabel("Importance Score")

        # 3ï¸âƒ£ ìƒˆë¡œìš´ ë°©ì‹: êµë€ëœ ì‹œê¸°ë³„ ì¤‘ìš”ë„ ë°” ê·¸ë˜í”„
        ax = axes[cls, 2]
        ax.bar(dates, time_importance[cls], color="darkorange")
        ax.set_title(f"{class_name}: Temporal Importance")
        ax.set_xlabel("Time (Dates)")
        ax.set_ylabel("Importance Score")
        ax.set_xticks(np.arange(num_times))
        ax.set_xticklabels(dates, rotation=45)  # ë‚ ì§œ ë¼ë²¨ ì ìš©

    plt.tight_layout()
    plt.show()
    
#attention ë¶„ì„
def compute_and_visualize_avg_attention(model, train_loader, num_classes, device):
    """
    1. TP(True Positive) ë°ì´í„° í•„í„°ë§
    2. ê° í´ë˜ìŠ¤ë³„ Attention Score Map ëˆ„ì  (ì²« ë²ˆì§¸ / ë§ˆì§€ë§‰ / ì „ì²´ í‰ê· )
    3. í´ë˜ìŠ¤ë³„ í‰ê·  Attention Map ê³„ì‚° í›„ ì‹œê°í™” (ê° í´ë˜ìŠ¤ë‹¹ 3ê°œ)
    """
    model.eval()
    num_layers = None

    class_attention_first = {c: torch.zeros(12, 12).to(device) for c in range(num_classes)}
    class_attention_last = {c: torch.zeros(12, 12).to(device) for c in range(num_classes)}
    class_attention_avg = {c: torch.zeros(12, 12).to(device) for c in range(num_classes)}
    
    class_count = {c: 0 for c in range(num_classes)}

    with torch.no_grad():
        for x, y in tqdm(train_loader, desc="Processing Batches", unit="batch"):
            x, y = x.to(device), y.to(device)

            # âœ… ëª¨ë¸ Forward Pass (Attention Score í¬í•¨)
            logits, attention_weights = model(x, return_attention=True)

            # ğŸ”¹ attention_weightsê°€ listì¸ ê²½ìš° tensorë¡œ ë³€í™˜
            if isinstance(attention_weights, list):
                attention_weights = torch.stack(attention_weights, dim=1)  # (batch, num_layers, heads, 12, 12)

            predictions = torch.argmax(logits, dim=1)  # ì˜ˆì¸¡ê°’ (batch,)

            if num_layers is None:
                num_layers = attention_weights.shape[1]

            # ğŸ”¹ TP ë°ì´í„° í•„í„°ë§ & Attention ëˆ„ì 
            for i in range(len(y)):
                true_label = y[i].item()
                pred_label = predictions[i].item()

                if true_label == pred_label:  # âœ… True Positiveë§Œ ì‚¬ìš©
                    
                    attn_first = attention_weights[i, 0].to(device)  # ì²« ë²ˆì§¸ ë ˆì´ì–´ í‰ê·  (12, 12)
                    attn_last = attention_weights[i, -1].to(device)  # ë§ˆì§€ë§‰ ë ˆì´ì–´ í‰ê·  (12, 12)
                    attn_avg = attention_weights[i].mean(dim=0).to(device)  # ì „ì²´ ë ˆì´ì–´ í‰ê·  (12, 12)
                    
                    class_attention_first[true_label] += attn_first
                    class_attention_last[true_label] += attn_last
                    class_attention_avg[true_label] += attn_avg
                    class_count[true_label] += 1

    # ğŸ”¹ í´ë˜ìŠ¤ë³„ í‰ê·  Attention Map ê³„ì‚° & ì‹œê°í™”
    for c in range(num_classes):
        if class_count[c] == 0:
            print(f"[ê²½ê³ ] í´ë˜ìŠ¤ {target_name_mapping[c]}ì˜ TP ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìŠ¤í‚µ)")
            continue
        
        avg_first = class_attention_first[c] / class_count[c]
        avg_last = class_attention_last[c] / class_count[c]
        avg_all = class_attention_avg[c] / class_count[c]

        # ğŸ”¹ ì‹œê°í™”
        for idx, (title, avg_attn) in enumerate([
            (f"Class {target_name_mapping[c]} - First Layer", avg_first),
            (f"Class {target_name_mapping[c]} - Last Layer", avg_last),
            (f"Class {target_name_mapping[c]} - All Layers Avg", avg_all),
        ]):
            plt.figure(figsize=(6, 5))
            sns.heatmap(avg_attn.cpu().numpy(), annot=False, cmap="viridis", square=True)
            plt.xlabel("Key Time Steps")
            plt.ylabel("Query Time Steps")
            plt.title(title)
            plt.show()

    print(f"âœ… {num_classes * 3} ê°œì˜ í‰ê·  Attention Mapì´ ì¶œë ¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
