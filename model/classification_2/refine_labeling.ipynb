{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import train_model, base_transform, evaluate_model_with_cm, TiffDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import copy\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"../../data/label_data/species/label_mapping_sampled.csv\")\n",
    "df_test = pd.read_csv(\"../../data/label_data/species/label_mapping_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['type'] = 'train'\n",
    "df_test['type'] = 'test'\n",
    "\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=6, kernel_size=3):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        # ResNet18 모델을 기반으로 사용\n",
    "        self.transform = transform\n",
    "        self.resnet = models.resnet18(weights=None)  # 사전 훈련 없이 초기화\n",
    "        self.resnet.conv1 = nn.Conv2d(in_channels, 64, kernel_size=kernel_size, stride=1, padding=1, bias=False)  # 입력 채널 9개로 변경\n",
    "        self.resnet.maxpool = nn.Identity()  # 5x5 입력이므로 MaxPooling 제거\n",
    "        self.resnet.fc = nn.Linear(512, num_classes)  # 마지막 출력 뉴런을 클래스 수에 맞게 변경\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, dim, expand_ratio=4, dropout=0.1):\n",
    "        super(FeedForwardBlock, self).__init__()\n",
    "        hidden_dim = dim * expand_ratio\n",
    "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, expand_ratio=4, dropout=0.1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.ffn = FeedForwardBlock(dim, expand_ratio, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.norm(x)\n",
    "        out = self.ffn(out)\n",
    "        return x + out  # Skip Connection\n",
    "\n",
    "class DNNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=10, hidden_dim=128, output_dim=6, num_layers=10, expand_ratio=4, dropout=0.1):\n",
    "        super(DNNClassifier, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layers = nn.Sequential(*[ResidualBlock(hidden_dim, expand_ratio, dropout) for _ in range(num_layers)])\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=10, embed_dim=16, num_heads=2, num_layers=2, num_classes=6, seq_len=12, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "\n",
    "        # Linear layer for embedding input_dim -> embed_dim\n",
    "        self.input_fc = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        # Transformer Encoder Layer 설정 (batch_first=True)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,  # 입력의 임베딩 차원\n",
    "            nhead=num_heads,  # Multi-head Attention의 head 개수\n",
    "            dropout=dropout,\n",
    "            batch_first=True  # 배치 차원이 첫 번째로 오도록 설정\n",
    "        )\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layer, num_layers=num_layers  # Encoder Layer의 수\n",
    "        )\n",
    "        \n",
    "        # 마지막 출력에서 분류를 위한 Linear Layer\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "        #가중치 초기화\n",
    "        self._init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 입력을 임베딩 차원으로 변환\n",
    "        x = self.input_fc(x)\n",
    "        \n",
    "        # Transformer Encoder 통과\n",
    "        transformer_out = self.transformer_encoder(x)\n",
    "        \n",
    "        # transformer_out의 마지막 시퀀스에 해당하는 출력을 가져옵니다.\n",
    "        # (batch, seq_len, embed_dim) -> (batch, embed_dim)\n",
    "        out = transformer_out[:, -1, :]\n",
    "        \n",
    "        # FC Layer를 통한 분류\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.TransformerEncoderLayer):\n",
    "                nn.init.xavier_uniform_(m.linear1.weight)\n",
    "                nn.init.xavier_uniform_(m.linear2.weight)\n",
    "                if m.linear1.bias is not None:\n",
    "                    nn.init.zeros_(m.linear1.bias)\n",
    "                if m.linear2.bias is not None:\n",
    "                    nn.init.zeros_(m.linear2.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def get_gaussian_kernel(kernel_size, sigma):\n",
    "    \"\"\"\n",
    "    2D Gaussian Kernel 생성\n",
    "    \"\"\"\n",
    "    ax = torch.arange(kernel_size, dtype=torch.float32) - (kernel_size - 1) / 2\n",
    "    xx, yy = torch.meshgrid(ax, ax, indexing='ij')\n",
    "    kernel = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "    kernel /= kernel.sum()\n",
    "    return kernel\n",
    "\n",
    "class DownsampleWithGaussian:\n",
    "    def __init__(self, kernel_size: int, sigma: float = None):\n",
    "        \"\"\"\n",
    "        kernel_size: 가우시안 필터 크기\n",
    "        sigma: 가우시안 필터의 표준편차 (None일 경우 기본값 자동 설정)\n",
    "        \"\"\"\n",
    "        self.kernel_size = kernel_size\n",
    "        if sigma is None:\n",
    "            sigma = 0.3 * ((kernel_size - 1) * 0.5 - 1) + 0.8  # 일반적인 디폴트 값\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        # 가우시안 커널 생성\n",
    "        kernel = get_gaussian_kernel(kernel_size, sigma)\n",
    "        self.kernel = kernel.view(1, 1, kernel_size, kernel_size)  # (1, 1, K, K)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (B, T, H, W)\n",
    "        Returns: Downsampled Tensor of shape (B, T, H//kernel_size, W//kernel_size)\n",
    "        \"\"\"\n",
    "        B, T, H, W = x.shape\n",
    "  \n",
    "        if H % self.kernel_size != 0 or W % self.kernel_size != 0:\n",
    "            raise ValueError(f\"Input size ({H}, {W}) must be divisible by kernel_size {self.kernel_size}\")\n",
    "        \n",
    "        # 채널 차원 추가 후 Gaussian Blur 적용\n",
    "        x = x.contiguous().view(B * T, 1, H, W)  # (B*T, 1, H, W)\n",
    "        x_blurred = F.conv2d(x, self.kernel.to(x.device), stride=self.kernel_size, padding=0)  # (B*T, 1, H//K, W//K)\n",
    "        \n",
    "        return x_blurred.view(B, T, H // self.kernel_size, W // self.kernel_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, scheduler=None):\n",
    "    \n",
    "    if patience == None:\n",
    "        patience= num_epochs\n",
    "        \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_f1_score = 0\n",
    "    best_model_state = model.state_dict()  # 초기 모델 가중치 저장\n",
    "    no_improve_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        \n",
    "        train_labels = []\n",
    "        train_predictions = []\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += loss.item() * labels.size(0)  # 배치별 loss * 개수로 전체 손실 계산\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "            train_predictions.extend(predicted.cpu().numpy())\n",
    "            \n",
    "        train_loss = train_running_loss / len(train_loader.dataset)  # 전체 샘플 수로 나눔\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        full_class_labels = np.arange(outputs.shape[1])\n",
    "        train_report = classification_report(train_labels, train_predictions, labels=full_class_labels, output_dict=True)\n",
    "        \n",
    "        print(f\"\\nEpoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_report['accuracy']:.2f}, Train f1-score: {train_report[\"macro avg\"][\"f1-score\"]:.2f} \")       \n",
    "       \n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(val_loss)  # validation loss 기준\n",
    "            else:\n",
    "                scheduler.step()  # 일반적인 step()\n",
    "    \n",
    "    return best_model_state, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>file</th>\n",
       "      <th>box_number</th>\n",
       "      <th>tree_species</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1060</td>\n",
       "      <td>1063</td>\n",
       "      <td>jiri_1.tif</td>\n",
       "      <td>23</td>\n",
       "      <td>QM</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>463</td>\n",
       "      <td>997</td>\n",
       "      <td>jiri_1.tif</td>\n",
       "      <td>22</td>\n",
       "      <td>QM</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>889</td>\n",
       "      <td>1147</td>\n",
       "      <td>jiri_1.tif</td>\n",
       "      <td>33</td>\n",
       "      <td>QM</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>652</td>\n",
       "      <td>298</td>\n",
       "      <td>jiri_1.tif</td>\n",
       "      <td>2</td>\n",
       "      <td>QM</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>388</td>\n",
       "      <td>634</td>\n",
       "      <td>jiri_1.tif</td>\n",
       "      <td>12</td>\n",
       "      <td>QM</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14394</th>\n",
       "      <td>5</td>\n",
       "      <td>1078</td>\n",
       "      <td>568</td>\n",
       "      <td>sobaek.tif</td>\n",
       "      <td>13</td>\n",
       "      <td>QV</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14395</th>\n",
       "      <td>5</td>\n",
       "      <td>1126</td>\n",
       "      <td>505</td>\n",
       "      <td>sobaek.tif</td>\n",
       "      <td>14</td>\n",
       "      <td>QV</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14396</th>\n",
       "      <td>5</td>\n",
       "      <td>190</td>\n",
       "      <td>430</td>\n",
       "      <td>sobaek.tif</td>\n",
       "      <td>11</td>\n",
       "      <td>QV</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14397</th>\n",
       "      <td>5</td>\n",
       "      <td>3535</td>\n",
       "      <td>751</td>\n",
       "      <td>sobaek.tif</td>\n",
       "      <td>30</td>\n",
       "      <td>QV</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>5</td>\n",
       "      <td>1393</td>\n",
       "      <td>244</td>\n",
       "      <td>sobaek.tif</td>\n",
       "      <td>4</td>\n",
       "      <td>QV</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  x_pos  y_pos        file  box_number tree_species   type\n",
       "0          4   1060   1063  jiri_1.tif          23           QM  train\n",
       "1          4    463    997  jiri_1.tif          22           QM  train\n",
       "2          4    889   1147  jiri_1.tif          33           QM  train\n",
       "3          4    652    298  jiri_1.tif           2           QM  train\n",
       "4          4    388    634  jiri_1.tif          12           QM  train\n",
       "...      ...    ...    ...         ...         ...          ...    ...\n",
       "14394      5   1078    568  sobaek.tif          13           QV   test\n",
       "14395      5   1126    505  sobaek.tif          14           QV   test\n",
       "14396      5    190    430  sobaek.tif          11           QV   test\n",
       "14397      5   3535    751  sobaek.tif          30           QV   test\n",
       "14398      5   1393    244  sobaek.tif           4           QV   test\n",
       "\n",
       "[242500 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/label_data/species/label_mapping_concated.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242500, 228101, 14399, 242500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df_train),len(df_test), len(df_train) + len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "patience=None\n",
    "bands = 10\n",
    "patch_size = 9\n",
    "time_idx = 4 #5월초\n",
    "large_tif_dir = '../../data/source_data/with_s2' #원천데이터 주소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TiffDataset(\n\u001b[1;32m      2\u001b[0m             large_tif_dir \u001b[38;5;241m=\u001b[39m large_tif_dir,\n\u001b[1;32m      3\u001b[0m             file_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_1.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_2.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msobaek.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;66;03m#전체 지역을 모두 사용한다.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m             label_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/label_data/species/label_mapping_sampled.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m             box_filter_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m box_number: \u001b[38;5;129;01mnot\u001b[39;00m val_filter(box_number),\n\u001b[1;32m      6\u001b[0m             patch_size \u001b[38;5;241m=\u001b[39m patch_size,\n\u001b[1;32m      7\u001b[0m             transform\u001b[38;5;241m=\u001b[39mtransform\n\u001b[1;32m      8\u001b[0m         )\n\u001b[1;32m     10\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TiffDataset(\n\u001b[1;32m     11\u001b[0m             large_tif_dir \u001b[38;5;241m=\u001b[39m large_tif_dir,\n\u001b[1;32m     12\u001b[0m             file_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_1.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_2.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msobaek.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;66;03m#전체 지역을 모두 사용한다.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m             transform\u001b[38;5;241m=\u001b[39mtransform\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     19\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/my_study/forest_carbon_ai/model/classification_2/utils/utils.py:327\u001b[0m, in \u001b[0;36mTiffDataset.__init__\u001b[0;34m(self, large_tif_dir, file_list, label_file, patch_size, box_filter_fn, transform)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_filter_fn \u001b[38;5;241m=\u001b[39m box_filter_fn \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m box_number: \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list)]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_filter_fn)]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size \u001b[38;5;241m=\u001b[39m patch_size\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhalf_size \u001b[38;5;241m=\u001b[39m patch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/A/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/envs/A/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/A/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/A/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/envs/A/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(box_number)\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m TiffDataset(\n\u001b[1;32m      2\u001b[0m             large_tif_dir \u001b[38;5;241m=\u001b[39m large_tif_dir,\n\u001b[1;32m      3\u001b[0m             file_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_1.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_2.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msobaek.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;66;03m#전체 지역을 모두 사용한다.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m             label_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/label_data/species/label_mapping_sampled.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 5\u001b[0m             box_filter_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m box_number: \u001b[38;5;129;01mnot\u001b[39;00m val_filter(box_number),\n\u001b[1;32m      6\u001b[0m             patch_size \u001b[38;5;241m=\u001b[39m patch_size,\n\u001b[1;32m      7\u001b[0m             transform\u001b[38;5;241m=\u001b[39mtransform\n\u001b[1;32m      8\u001b[0m         )\n\u001b[1;32m     10\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m TiffDataset(\n\u001b[1;32m     11\u001b[0m             large_tif_dir \u001b[38;5;241m=\u001b[39m large_tif_dir,\n\u001b[1;32m     12\u001b[0m             file_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_1.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjiri_2.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msobaek.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;66;03m#전체 지역을 모두 사용한다.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m             transform\u001b[38;5;241m=\u001b[39mtransform\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     19\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_filter' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = TiffDataset(\n",
    "            large_tif_dir = large_tif_dir,\n",
    "            file_list = [\"jiri_1.tif\", \"jiri_2.tif\", \"sobaek.tif\"], #전체 지역을 모두 사용한다.\n",
    "            label_file = \"../../data/label_data/species/label_mapping_sampled.csv\",\n",
    "            box_filter_fn = lambda box_number: not val_filter(box_number),\n",
    "            patch_size = patch_size,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "val_dataset = TiffDataset(\n",
    "            large_tif_dir = large_tif_dir,\n",
    "            file_list = [\"jiri_1.tif\", \"jiri_2.tif\", \"sobaek.tif\"], #전체 지역을 모두 사용한다.\n",
    "            label_file =\"../../data/label_data/species/label_mapping_sampled.csv\",\n",
    "            box_filter_fn = val_filter,\n",
    "            patch_size = patch_size,\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      2\u001b[0m     base_transform(bands, patch_size),\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[:,time_idx])\n\u001b[1;32m      4\u001b[0m ])\n\u001b[0;32m----> 6\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[1;32m      7\u001b[0m val_dataset\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    base_transform(bands, patch_size),\n",
    "    transforms.Lambda(lambda x: x[:,time_idx])\n",
    "])\n",
    "\n",
    "train_dataset.transform = transform\n",
    "val_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetClassifier(in_channels=10).to(device)\n",
    "model.load_state_dict(torch.load(f\"./checkpoints/spectral/resnet_{bands}_{patch_size}_{kernel_size}_{num_epochs}.pth\"))\n",
    "# 🔹 Loss function (Categorical Classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 🔹 Optimizer (AdamW with weight decay)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# # 🔹 Learning Rate Scheduler (StepLR: 10 epochs마다 lr 0.1배 감소)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 파라미터 수 (학습 가능한 파라미터와 학습 불가능한 파라미터 포함)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# 학습 가능한 파라미터 수 (requires_grad == True인 파라미터)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"전체 파라미터 수:\", total_params)\n",
    "print(\"학습 가능한 파라미터 수:\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_state, train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience=patience)\n",
    "torch.save(best_model_state, os.path.join(checkpoints_dir, f\"resnet_{bands}_{patch_size}_{kernel_size}_{num_epochs}.pth\"))\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "print(\"\\ntrain data\")\n",
    "evaluate_model_with_cm(model, train_loader, num_classes=6)\n",
    "print(\"\\nvalidation data\")\n",
    "evaluate_model_with_cm(model, val_loader, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 메모리 정리\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_transform(x):\n",
    "    x = x.squeeze(-1).squeeze(-1)  # (10, 12, 1, 1) → (10, 12)\n",
    "    x = x.permute(1, 0)  # (10, 12) → (12, 10)\n",
    "    return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    base_transform(bands, patch_size),\n",
    "    DownsampleWithGaussian(kernel_size, sigma=3),\n",
    "    transforms.Lambda(reshape_transform)\n",
    "])\n",
    "\n",
    "train_dataset.transform = transform\n",
    "val_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  TransformerClassifier(input_dim=10, embed_dim=16, num_heads=2, num_layers=2, num_classes=6, seq_len=12).to(device)\n",
    "\n",
    "# 🔹 Loss function (Categorical Classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer 설정\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_state, train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience=patience)\n",
    "torch.save(best_model_state, os.path.join(checkpoints_dir, f\"transformer_{bands}_{patch_size}_{num_epochs}.pth\"))\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "print(\"\\ntrain data\")\n",
    "evaluate_model_with_cm(model, train_loader, num_classes=6)\n",
    "print(\"\\nvalidation data\")\n",
    "evaluate_model_with_cm(model, val_loader, num_classes=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A",
   "language": "python",
   "name": "a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
